{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff461ab0-d90b-4f73-9823-c64d986da016",
   "metadata": {},
   "source": [
    "# CIFAR-10 Optimizer Benchmark — Run Layout & Reproducibility\n",
    "\n",
    "> **Note:** We created a results folder because training was launched **outside this notebook**.  \n",
    "> There isn’t a single, continuous terminal log here. Each run wrote its own logs and summaries\n",
    "> into a dedicated subfolder. This notebook will **read/plot the saved artifacts** rather than\n",
    "> re-train everything inline.\n",
    "\n",
    "## What the training script does\n",
    "- Loads **CIFAR-10** with strong augmentation (RandomCrop/Flip, TrivialAugmentWide, RandomErasing) and normalization.\n",
    "- Builds the model:\n",
    "  - `--model resnet` → ResNet-18–style CNN.\n",
    "  - `--model vit` → small, CIFAR-friendly Vision Transformer (pre-norm, patch size 4).\n",
    "- Picks the optimizer:\n",
    "  - `--opt adam`  → AdamW baseline.\n",
    "  - `--opt muon`  → Newton–Schulz orthonormal updates on 2D weights; AdamW on IO/scalars.\n",
    "  - `--opt scion` → spectral step for hidden matrices; ℓ∞ step for IO/scalars.\n",
    "  - `--opt dion`  → low-rank orthonormal update (with error-feedback) + AdamW on IO/scalars.\n",
    "- Trains for `--epochs 80` with **AMP** (`--amp`), logs **loss/accuracy/time** per epoch, and saves:\n",
    "  - per-run CSVs (metrics by epoch),\n",
    "  - a summary JSON,\n",
    "  - optional plots (if enabled in the script).\n",
    "\n",
    "### Key flags\n",
    "- `--model {resnet|vit}`: choose architecture  \n",
    "- `--opt {adam|muon|scion|dion}`: choose optimizer  \n",
    "- `--epochs 80`: training length  \n",
    "- `--amp`: enable mixed precision  \n",
    "- `--out_dir ./results/<name>`: where logs/CSVs/summaries are saved\n",
    "\n",
    "## Exact commands used\n",
    "Specific commands used to train the models, it took us about 2 hours to run on RTX5090. To modify the other default parameters either refer to Args dataclass in trianing.py, or pass additional arguments in the CLIs that follows the naming in the training.py.\n",
    "```bash\n",
    "# ResNet18 + Optimizers\n",
    "python training.py --model resnet --opt adam  --epochs 80 --amp --out_dir ./results/resnet_adam\n",
    "python training.py --model resnet --opt dion  --epochs 80 --amp --out_dir ./results/resnet_dion\n",
    "python training.py --model resnet --opt muon  --epochs 80 --amp --out_dir ./results/resnet_muon\n",
    "python training.py --model resnet --opt scion --epochs 80 --amp --out_dir ./results/resnet_scion\n",
    "\n",
    "# MiniViT (ViT-small for CIFAR) + Optimizers\n",
    "python training.py --model vit --opt adam  --epochs 80 --amp --out_dir ./results/vit_adam\n",
    "python training.py --model vit --opt dion  --epochs 80 --amp --out_dir ./results/vit_dion\n",
    "python training.py --model vit --opt muon  --epochs 80 --amp --out_dir ./results/vit_muon\n",
    "python training.py --model vit --opt scion --epochs 80 --amp --out_dir ./results/vit_scion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b345febf",
   "metadata": {},
   "source": [
    "The script below collects the outcomes of **all training runs** stored under `./results/`\n",
    "(e.g., `resnet_adam/`, `vit_dion/`, …) and builds a **single, unified view** of the experiment.\n",
    "\n",
    "What it does\n",
    "1. **Scan** each run folder in `./results/`.\n",
    "2. **Load metrics** from per-run CSV/JSON (epoch-wise loss, accuracy, epoch time, best/final accuracy).\n",
    "3. **Assemble a summary table** (`summary_results.csv`) with one row per (model, optimizer) run.\n",
    "4. **Generate comparison plots**:\n",
    "   - `train_loss_vs_epoch.png`\n",
    "   - `val_acc_vs_epoch.png`\n",
    "   - `val_acc_vs_time.png` (accuracy vs. cumulative training time)\n",
    "   - `best_val_acc_bar.png` (best accuracy across runs)\n",
    "   - `time_to_60_bar.png`\n",
    "   -  `time_to_70_bar.png` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa728049-72b9-4638-b031-b317b9419570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done.\n",
      " - Summary: ./report\\summary_results.csv\n",
      " - Per-epoch: ./report\\epoch_metrics_long.csv\n",
      " - Graphs in: ./report\n"
     ]
    }
   ],
   "source": [
    "from visualizations import main\n",
    "\n",
    "# save plots in png, save data in csv\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b980e1b-8356-4d87-b30c-3a97bd183b02",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "Across all figures, the ResNet experiments show that Adam, Muon, and Scion converge to a narrow band of high final accuracy, while Dion trails by several points. \n",
    "In the “best validation accuracy” bar plot, the three leading methods for ResNet cluster in the low-90% range, with Scion and Muon marginally ahead and Adam essentially tied within visual uncertainty; Dion is clearly lower. \n",
    "\n",
    "The milestone-time plots (“time to 60%/70%”) indicate that Scion and Adam reach useful accuracy fastest on ResNet, with Muon requiring more wall-clock and Dion the slowest.\n",
    "These patterns are consistent with the Scion design—spectral control on hidden layers and $\\ell_\\infty$ scaling on I/O layers—which the paper argues should stabilize early updates and enable aggressive learning rates. These are likewise consistent with Muon’s Newton–Schulz orthonormalization, which improves conditioning but adds per-step computation, often yielding slower early-phase progress yet competitive or superior late-epoch accuracy on models with substantial 2D linear structure. \n",
    "Dion’s underperformance on ResNet is expected in this configuration: the method is primarily targeted at distributed training and does not natively support convolutional kernels.\n",
    "\n",
    "For the Vision Transformer, the ordering differs: the “best validation accuracy” plot places Adam first (low-80% range) with Scion a close second, Muon lower, and Dion substantially lower. \n",
    "The milestone-time figures show that Scion tends to reach 60% and 70% sooner than Adam on the ViT, but the final accuracy favors Adam under the present recipe, a result aligned with common practice on small/medium ViTs where Adam(W) with cosine scheduling and moderate regularization remains a strong baseline.\n",
    "\n",
    "Taken together, the findings align with the central claims of the referenced works once scale and architectural fit are considered.\n",
    "- Scion demonstrates the expected early-epoch acceleration and retains competitive final accuracy, particularly on ResNet. \n",
    "- Muon exhibits the anticipated trade-off—more expensive updates but good conditioning—and would be expected to realize larger gains on longer runs or larger, linear-heavy models after modest sweeps of learning rate and Newton–Schulz iterations.\n",
    "- Dion is optimized for synchronous, communication-efficient training at scale, which isn’t fully exercised on one GPU. Its missing native conv support is not perfect for CIFAR-10/ResNet, nevertheless, it remains slightly advantageous here.\n",
    "- Adam remains a strong general-purpose baseline, especially for small ViTs under standard training protocols."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
